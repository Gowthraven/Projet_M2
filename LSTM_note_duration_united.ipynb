{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f7d15fe",
   "metadata": {},
   "source": [
    "# Génération de partition de musique : réseau LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53af2a1",
   "metadata": {},
   "source": [
    "**/!\\ Les notes et leurs durées sont liées lors de la phase d'apprentissage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8fa63b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\melan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.18) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\melan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import music21\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('C:/Users/melan/Documents/M2_S10 IAFA/CHEF D\\'OEUVRE')\n",
    "import extract_data as ed\n",
    "import visualization as vz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d650f3a",
   "metadata": {},
   "source": [
    "### Choix de la partie à générer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ec53db",
   "metadata": {},
   "outputs": [],
   "source": [
    "part = 'A'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b08848",
   "metadata": {},
   "source": [
    "### Préparation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f3fd74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the required variables\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc79719b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 171\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/data.json\",'r') as file:\n",
    "    data = json.load(file)\n",
    "                \n",
    "filenames = [data[i]['title'] for i in range(len(data))]\n",
    "print('Number of scores:', len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885c6c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores for :\n",
      "  - part A : 169\n",
      "  - part B : 166\n",
      "  - part C : 98\n"
     ]
    }
   ],
   "source": [
    "# Enregistrement des listes des parties A, B et C de toutes les melodies de data.json\n",
    "all_datasets = ed.json_into_part_melody(\"data/data.json\")\n",
    "print(\"Number of scores for :\")\n",
    "print(\"  - part A :\",all_datasets[0])\n",
    "print(\"  - part B :\",all_datasets[1])\n",
    "print(\"  - part C :\",all_datasets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "888d6ed5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/dataset\"+part+\".json\",'r') as file:\n",
    "    dataset = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "924c28c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La note E6 a un numéro MIDI de 88\n"
     ]
    }
   ],
   "source": [
    "from music21 import note\n",
    "\n",
    "# Créez un objet Note avec la note E6\n",
    "e6_note = note.Note(\"E6\")\n",
    "\n",
    "# Obtenez le numéro MIDI de la note\n",
    "midi_number = e6_note.pitch.midi\n",
    "\n",
    "# Affichez le résultat\n",
    "print(f\"La note E6 a un numéro MIDI de {midi_number}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1969a915",
   "metadata": {},
   "source": [
    "Choix de l'encodage\n",
    "- note : convertie avec music21\n",
    "- temps : duration * 0.1\n",
    "\n",
    "=> note finale : note + temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00c25e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode_notes(score):\n",
    "    \n",
    "    notes = [n for n in score.split(\",\")]\n",
    "    encoded_notes = []\n",
    "\n",
    "    for n in notes:\n",
    "        \n",
    "        splitted = n.replace(\" \",\"\").split('-')\n",
    "\n",
    "        if len(splitted) == 2:\n",
    "            \n",
    "            if splitted[0] == 'rest':\n",
    "                final_encoding = float(splitted[1]) * 0.1\n",
    "                encoded_notes.append(final_encoding)\n",
    "                \n",
    "            else:\n",
    "                only_note,duration = note.Note(splitted[0]).pitch.midi,float(splitted[1])\n",
    "                final_encoding = only_note + duration * 0.1\n",
    "                encoded_notes.append(final_encoding)\n",
    "        \n",
    "        else:\n",
    "            only_note = note.Note(\"b\".join(substring for substring in splitted[:-1])).pitch.midi\n",
    "            duration = float(splitted[-1])\n",
    "            final_encoding = only_note + duration * 0.1\n",
    "            encoded_notes.append(final_encoding)\n",
    "            \n",
    "    return encoded_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ce3a0",
   "metadata": {},
   "source": [
    "### Création du dataset d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f940c389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of notes parsed for part A : 19175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(1,), dtype=tf.float64, name=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_notes = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    \n",
    "    notes = pd.DataFrame(tokenize_and_encode_notes(dataset[i]))\n",
    "    all_notes.append(notes)\n",
    "\n",
    "all_notes = pd.concat(all_notes)\n",
    "\n",
    "n_notes = len(all_notes)\n",
    "print('Number of notes parsed for part',part,':', n_notes)\n",
    "\n",
    "train_notes = np.array(all_notes)\n",
    "\n",
    "notes_ds = tf.data.Dataset.from_tensor_slices(train_notes)\n",
    "\n",
    "notes_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a8861d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_sequences(dataset, seq_length):\n",
    "    \"\"\"Returns TF Dataset of sequence and label examples.\"\"\"\n",
    "    \n",
    "    seq_length = seq_length+1\n",
    "\n",
    "    # Take 1 extra for the labels\n",
    "    windows = dataset.window(seq_length, shift=1, stride=1,\n",
    "                              drop_remainder=True)\n",
    "\n",
    "    # `flat_map` flattens the\" dataset of datasets\" into a dataset of tensors\n",
    "    flatten = lambda x: x.batch(seq_length, drop_remainder=True)\n",
    "    sequences = windows.flat_map(flatten)\n",
    "\n",
    "    # Split the labels\n",
    "    def split_labels(sequences):\n",
    "        inputs = sequences[:-1]\n",
    "        labels_dense = sequences[-1]\n",
    "\n",
    "        return inputs,labels_dense\n",
    "\n",
    "    return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "seq_length = 50\n",
    "seq_ds = create_sequences(notes_ds, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "886a8d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(32, 50, 1), dtype=tf.float64, name=None), TensorSpec(shape=(32, 1), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "buffer_size = n_notes - seq_length  # the number of items in the dataset\n",
    "train_ds = (seq_ds\n",
    "            .shuffle(buffer_size)\n",
    "            .batch(batch_size, drop_remainder=True)\n",
    "            .cache()\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84098559",
   "metadata": {},
   "source": [
    "### Développement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40d8da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_with_positive_pressure(y_true, y_pred):\n",
    "    mse = (y_true - y_pred) ** 2\n",
    "    positive_pressure = 10 * tf.maximum(-y_pred, 0.0)\n",
    "    return tf.reduce_mean(mse + positive_pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "827f2793",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 50, 1)]           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                16896     \n",
      "                                                                 \n",
      " note (Dense)                (None, 128)               8320      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25216 (98.50 KB)\n",
      "Trainable params: 25216 (98.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Developing the model\n",
    "\n",
    "input_shape = (seq_length,1)\n",
    "learning_rate = 0.005\n",
    "\n",
    "inputs = Input(input_shape)\n",
    "x = LSTM(64)(inputs)\n",
    "\n",
    "outputs = {'note': Dense(128, name='note')(x),\n",
    "          }\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "loss = {'note': SparseCategoricalCrossentropy(from_logits=True),\n",
    "       }\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "763dea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the necessary callbacks\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath='./training_checkpoints/ckpt_{epoch}', save_weights_only=True),\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, \n",
    "                                              verbose=1, restore_best_weights=True),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "179d2005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "597/597 [==============================] - 16s 18ms/step - loss: 3.1017\n",
      "Epoch 2/50\n",
      "597/597 [==============================] - 11s 19ms/step - loss: 2.8639\n",
      "Epoch 3/50\n",
      "597/597 [==============================] - 11s 19ms/step - loss: 2.7798\n",
      "Epoch 4/50\n",
      "597/597 [==============================] - 13s 22ms/step - loss: 2.7441\n",
      "Epoch 5/50\n",
      "597/597 [==============================] - 13s 22ms/step - loss: 2.7362\n",
      "Epoch 6/50\n",
      "597/597 [==============================] - 13s 21ms/step - loss: 2.7168\n",
      "Epoch 7/50\n",
      "597/597 [==============================] - 12s 20ms/step - loss: 2.6983\n",
      "Epoch 8/50\n",
      "597/597 [==============================] - 12s 21ms/step - loss: 2.6889\n",
      "Epoch 9/50\n",
      "597/597 [==============================] - 12s 20ms/step - loss: 2.6824\n",
      "Epoch 10/50\n",
      "597/597 [==============================] - 12s 20ms/step - loss: 2.6753\n",
      "Epoch 11/50\n",
      "597/597 [==============================] - 12s 20ms/step - loss: 2.6890\n",
      "Epoch 12/50\n",
      "597/597 [==============================] - 12s 20ms/step - loss: 2.6700\n",
      "Epoch 13/50\n",
      "597/597 [==============================] - 12s 20ms/step - loss: 2.6618\n",
      "Epoch 14/50\n",
      "597/597 [==============================] - 13s 21ms/step - loss: 2.6558\n",
      "Epoch 15/50\n",
      "597/597 [==============================] - 13s 22ms/step - loss: 2.6511\n",
      "Epoch 16/50\n",
      "597/597 [==============================] - 13s 22ms/step - loss: 2.6482\n",
      "Epoch 17/50\n",
      "597/597 [==============================] - 13s 22ms/step - loss: 2.6450\n",
      "Epoch 18/50\n",
      "597/597 [==============================] - 12s 21ms/step - loss: 2.6389\n",
      "Epoch 19/50\n",
      "597/597 [==============================] - 12s 20ms/step - loss: 2.6352\n",
      "Epoch 20/50\n",
      "597/597 [==============================] - 13s 22ms/step - loss: 2.6313\n",
      "Epoch 21/50\n",
      "597/597 [==============================] - 14s 24ms/step - loss: 2.6285\n",
      "Epoch 22/50\n",
      "597/597 [==============================] - 14s 23ms/step - loss: 2.6286\n",
      "Epoch 23/50\n",
      "597/597 [==============================] - 14s 24ms/step - loss: 2.6216\n",
      "Epoch 24/50\n",
      "597/597 [==============================] - 17s 29ms/step - loss: 2.6188\n",
      "Epoch 25/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.6164\n",
      "Epoch 26/50\n",
      "597/597 [==============================] - 18s 31ms/step - loss: 2.6121\n",
      "Epoch 27/50\n",
      "597/597 [==============================] - 18s 31ms/step - loss: 2.6088\n",
      "Epoch 28/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.6093\n",
      "Epoch 29/50\n",
      "597/597 [==============================] - 18s 31ms/step - loss: 2.6038\n",
      "Epoch 30/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.6006\n",
      "Epoch 31/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.5985\n",
      "Epoch 32/50\n",
      "597/597 [==============================] - 18s 31ms/step - loss: 2.5983\n",
      "Epoch 33/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.5940\n",
      "Epoch 34/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.5907\n",
      "Epoch 35/50\n",
      "597/597 [==============================] - 18s 31ms/step - loss: 2.5886\n",
      "Epoch 36/50\n",
      "597/597 [==============================] - 19s 31ms/step - loss: 2.5868\n",
      "Epoch 37/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.5848\n",
      "Epoch 38/50\n",
      "597/597 [==============================] - 17s 29ms/step - loss: 2.5828\n",
      "Epoch 39/50\n",
      "597/597 [==============================] - 18s 29ms/step - loss: 2.5813\n",
      "Epoch 40/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.5818\n",
      "Epoch 41/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.5756\n",
      "Epoch 42/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.5733\n",
      "Epoch 43/50\n",
      "597/597 [==============================] - 18s 29ms/step - loss: 2.5711\n",
      "Epoch 44/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.5710\n",
      "Epoch 45/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.5684\n",
      "Epoch 46/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.5663\n",
      "Epoch 47/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.5649\n",
      "Epoch 48/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.5645\n",
      "Epoch 49/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.5623\n",
      "Epoch 50/50\n",
      "597/597 [==============================] - 18s 30ms/step - loss: 2.5622\n"
     ]
    }
   ],
   "source": [
    "# Compiling and fitting the model\n",
    "\n",
    "model.compile(loss = loss, \n",
    "              optimizer = optimizer)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "history = model.fit(train_ds, \n",
    "                    epochs=epochs,\n",
    "                   callbacks=callbacks,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ddd69a",
   "metadata": {},
   "source": [
    "### Génération de notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58335a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_note(notes, model, temperature = 1.0):\n",
    "    \"\"\"Generates a note IDs using a trained sequence model.\"\"\"\n",
    "\n",
    "    assert temperature > 0\n",
    "\n",
    "    # Add batch dimension\n",
    "    inputs = tf.expand_dims(notes, 0)\n",
    "\n",
    "    predictions = model.predict(inputs)\n",
    "    note_logits = predictions['note']\n",
    "\n",
    "    note_logits /= temperature\n",
    "    note = tf.random.categorical(note_logits, num_samples=1)\n",
    "    note = tf.squeeze(note, axis=-1)\n",
    "\n",
    "    return float(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "159d3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_note(generated_note):\n",
    "    \n",
    "    quarter_duration = [0.0625,0.125,0.25,0.5,1.0,2.0]\n",
    "    \n",
    "    if int(generated_note) == 0:\n",
    "        duration = min(quarter_duration, key=lambda x:abs(x-(10 * generated_note)))\n",
    "        return \"rest-\"+str(duration)\n",
    "    \n",
    "    else:\n",
    "        duration = min(quarter_duration, key=lambda x:abs(x-(10 * (generated_note - round(generated_note)))))\n",
    "        note = music21.pitch.Pitch()\n",
    "        note.midi = round(generated_note)\n",
    "        return str(note.nameWithOctave)+\"-\"+str(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1f79bae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generated_notes_to_dict(score,temperature=2.0,num_predictions=8):\n",
    "    \n",
    "    raw_notes = tokenize_and_encode_notes(score)\n",
    "    sample_notes = np.array(raw_notes)\n",
    "    input_notes = sample_notes[:8]\n",
    "    \n",
    "    original_notes = [decoding_note(n) for n in sample_notes]\n",
    "    initial_notes = original_notes[:8]\n",
    "    \n",
    "    generated_notes = []\n",
    "    \n",
    "    for _ in range(num_predictions):\n",
    "        \n",
    "        note = predict_next_note(input_notes, model)\n",
    "        dec_note = decoding_note(note)\n",
    "        generated_notes.append(dec_note)\n",
    "        \n",
    "        input_notes = np.delete(note, 0)\n",
    "        input_notes = np.append(note, np.expand_dims(note, 0))\n",
    "    \n",
    "    return {'Title':'','Part':part,'Key':\"F major\",'Start_sequence':initial_notes,'Generated':generated_notes,'Original':original_notes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a979fa6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "B-5-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "E7-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "E6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "F#7-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "D6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "B4-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "C6-0.0625\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "B-5-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "E7-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "G7-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "A5-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "D6-0.0625\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "G4-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "rest-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "C1-0.0625\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "F4-0.0625\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "G5-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "F6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "F6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "D5-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "C#6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "A6-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "F#7-0.0625\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "E-7-0.0625\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "C6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "rest-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "G#4-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "E5-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "D6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "E6-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "A6-0.0625\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "F7-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "A6-0.0625\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "rest-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "E-9-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "C6-0.0625\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "E6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "D6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "F6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "F#4-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "A5-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "E6-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "F#7-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "G#6-0.0625\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "A5-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "D5-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "A5-0.0625\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "F6-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "G#6-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "E-7-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "C6-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "G#4-0.0625\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "E-5-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "C6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "E7-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "E7-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "E-7-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "D4-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "F5-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "E-7-0.0625\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "C6-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "E-6-0.0625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "A6-0.0625\n"
     ]
    }
   ],
   "source": [
    "generated_scores = []\n",
    "\n",
    "for f in dataset[:10]:\n",
    "    \n",
    "    gen_notes = generated_notes_to_dict(f)\n",
    "    generated_scores.append(gen_notes)\n",
    "    \n",
    "with open('Generated/LSTM_'+part+'.json','w') as file:\n",
    "    json.dump(generated_scores,file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c31903b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "music21.environment.set('musescoreDirectPNGPath',str(os.path.join(\"C:\\\\\", \"Program Files\",\"MuseScore 4\",\"bin\",\"MuseScore4.exe\")))\n",
    "music21.environment.set('musicxmlPath', str(os.path.join(\"C:\\\\\", \"Program Files\",\"MuseScore 4\",\"bin\",\"MuseScore4.exe\")))\n",
    "vz.show_all_generated(\"Generated/LSTM_\"+part+\".json\").show(\"musicxml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
